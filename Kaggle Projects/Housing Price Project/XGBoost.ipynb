{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Libraries\n",
    "from sklearn.ensemble import RandomForestRegressor,StackingRegressor,GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge,Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import RandomizedSearchCV,cross_val_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from xgboost import XGBRegressor\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv(\n",
    "    r'C:\\Users\\ahmad\\Documents\\Coding Projects\\Kaggle Projects\\house-prices-advanced-regression-techniques\\train.csv') \n",
    "df_test = pd.read_csv(\n",
    "    r'C:\\Users\\ahmad\\Documents\\Coding Projects\\Kaggle Projects\\house-prices-advanced-regression-techniques\\test.csv'\n",
    ")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to find General Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 81)\n"
     ]
    }
   ],
   "source": [
    "#function that gives the following information for each column\n",
    "    # 1. number of unique values \n",
    "    # 2. the data type \n",
    "    # 3. the null ratio \n",
    "def general_info(x):\n",
    "    # Get unique values and data types in each column\n",
    "    datatypes = x.dtypes\n",
    "    unique_values = x.nunique()\n",
    "    #get null ratio for each column\n",
    "    nulls = x.isnull().sum()\n",
    "    nullratios = nulls / x.shape[0]\n",
    "    general_info = pd.DataFrame({'datatype': datatypes,'unique_values' : unique_values,'nullratios': nullratios})\n",
    "    #print(general_info)\n",
    "    return general_info\n",
    "info = general_info(df)\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that cleans NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means:  LotFrontage      70.049958\n",
      "MasVnrArea      103.685262\n",
      "GarageYrBlt    1978.506164\n",
      "dtype: float64\n",
      "             datatype  unique_values  nullratios\n",
      "BsmtQual       object              4    0.025342\n",
      "BsmtCond       object              4    0.025342\n",
      "BsmtExposure   object              4    0.026027\n",
      "BsmtFinType1   object              6    0.025342\n",
      "BsmtFinType2   object              6    0.026027\n",
      "Electrical     object              5    0.000685\n",
      "GarageType     object              6    0.055479\n",
      "GarageFinish   object              3    0.055479\n",
      "GarageQual     object              5    0.055479\n",
      "GarageCond     object              5    0.055479\n",
      "Empty DataFrame\n",
      "Columns: [datatype, unique_values, nullratios]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# function that cleans the data set by doing the following:\n",
    "# 1. remove all columns with more than 25% missing data\n",
    "# 2 fill all missing float data types with the mean value of their column\n",
    "# 3. fill all missing categorical data with most previously filled category within that column\n",
    "def clean_NaNs(x, info_x, x_test):\n",
    "    # keep all rows with less than 25% NaN values\n",
    "    x = x.loc[:, info_x[\"nullratios\"] < 0.25]\n",
    "    x_test = x_test[x.columns[x.columns != \"SalePrice\"]]\n",
    "    info_x = general_info(x)\n",
    "    # fix all the NaNs where floats becomes means\n",
    "    float_nan_columns = info_x[\n",
    "        (info_x[\"datatype\"] == \"float64\") & (info_x[\"nullratios\"] > 0)\n",
    "    ].index.tolist()\n",
    "    # print(float_nan_columns)\n",
    "    means = x[float_nan_columns].mean()\n",
    "    print(\"means: \", means)\n",
    "    x.loc[:, float_nan_columns] = x[float_nan_columns].fillna(means)\n",
    "    x_test.loc[:, float_nan_columns] = x_test[float_nan_columns].fillna(means)\n",
    "    info_x = general_info(x)\n",
    "    print(info_x.loc[info_x[\"nullratios\"] > 0, :])\n",
    "    # fix all the NaNs where objects becomes ffill()\n",
    "    x = x.ffill()\n",
    "    x_test = x_test.ffill()\n",
    "    info_x = general_info(x)\n",
    "    print(info_x.loc[info_x[\"nullratios\"] > 0, :])\n",
    "    # fix info\n",
    "    return x, info_x, x_test\n",
    "\n",
    "\n",
    "df, info, df_test = clean_NaNs(df, info, df_test)\n",
    "# print(info.loc[info['nullratios']>0,:]) # should have no outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions that do Label Encoding or One-Hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 75)\n",
      "['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'SaleType', 'SaleCondition']\n",
      "   Id  MSSubClass  MSZoning  LotFrontage  LotArea  Street  LotShape  LandContour  Utilities  LotConfig  LandSlope  Neighborhood  Condition1  Condition2  BldgType  HouseStyle  OverallQual  OverallCond  YearBuilt  YearRemodAdd  RoofStyle  RoofMatl  Exterior1st  Exterior2nd  MasVnrArea  ExterQual  ExterCond  Foundation  BsmtQual  BsmtCond  BsmtExposure  BsmtFinType1  BsmtFinSF1  BsmtFinType2  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  Heating  HeatingQC  CentralAir  Electrical  1stFlrSF  2ndFlrSF  LowQualFinSF  GrLivArea  BsmtFullBath  BsmtHalfBath  FullBath  HalfBath  BedroomAbvGr  KitchenAbvGr  KitchenQual  TotRmsAbvGrd  Functional  Fireplaces  GarageType  GarageYrBlt  GarageFinish  GarageCars  GarageArea  GarageQual  GarageCond  PavedDrive  WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  MiscVal  MoSold  YrSold  SaleType  SaleCondition  SalePrice\n",
      "0   1          60         3         65.0     8450       1         3            3          0          4          0             5           2           2         0           5            7            5       2003          2003          1         1           12           13       196.0          2          4           2         2         3             3             2         706             5           0        150          856        1          0           1           4       856       854             0       1710             1             0         2         1             3             1            2             8           6           0           1       2003.0             1           2         548           4           4           2           0           61              0          0            0         0        0       2    2008         8              4     208500\n",
      "1   2          20         3         80.0     9600       1         3            3          0          2          0            24           1           2         0           2            6            8       1976          1976          1         1            8            8         0.0          3          4           1         2         3             1             0         978             5           0        284         1262        1          0           1           4      1262         0             0       1262             0             1         2         0             3             1            3             6           6           1           1       1976.0             1           2         460           4           4           2         298            0              0          0            0         0        0       5    2007         8              4     181500\n",
      "2   3          60         3         68.0    11250       1         0            3          0          4          0             5           2           2         0           5            7            5       2001          2002          1         1           12           13       162.0          2          4           2         2         3             2             2         486             5           0        434          920        1          0           1           4       920       866             0       1786             1             0         2         1             3             1            2             6           6           1           1       2001.0             1           2         608           4           4           2           0           42              0          0            0         0        0       9    2008         8              4     223500\n",
      "3   4          70         3         60.0     9550       1         0            3          0          0          0             6           2           2         0           5            7            5       1915          1970          1         1           13           15         0.0          3          4           0         3         1             3             0         216             5           0        540          756        1          2           1           4       961       756             0       1717             1             0         1         0             3             1            2             7           6           1           5       1998.0             2           3         642           4           4           2           0           35            272          0            0         0        0       2    2006         8              0     140000\n",
      "4   5          60         3         84.0    14260       1         0            3          0          2          0            15           2           2         0           5            8            5       2000          2000          1         1           12           13       350.0          2          4           2         2         3             0             2         655             5           0        490         1145        1          0           1           4      1145      1053             0       2198             1             0         2         1             4             1            2             9           6           1           1       2000.0             1           3         836           4           4           2         192           84              0          0            0         0        0      12    2008         8              4     250000\n",
      "     Id  MSSubClass  MSZoning  LotFrontage  LotArea  Street  LotShape  LandContour  Utilities  LotConfig  LandSlope  Neighborhood  Condition1  Condition2  BldgType  HouseStyle  OverallQual  OverallCond  YearBuilt  YearRemodAdd  RoofStyle  RoofMatl  Exterior1st  Exterior2nd  MasVnrArea  ExterQual  ExterCond  Foundation  BsmtQual  BsmtCond  BsmtExposure  BsmtFinType1  BsmtFinSF1  BsmtFinType2  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  Heating  HeatingQC  CentralAir  Electrical  1stFlrSF  2ndFlrSF  LowQualFinSF  GrLivArea  BsmtFullBath  BsmtHalfBath  FullBath  HalfBath  BedroomAbvGr  KitchenAbvGr  KitchenQual  TotRmsAbvGrd  Functional  Fireplaces  GarageType  GarageYrBlt  GarageFinish  GarageCars  GarageArea  GarageQual  GarageCond  PavedDrive  WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  MiscVal  MoSold  YrSold  SaleType  SaleCondition\n",
      "0  1461          20         2         80.0    11622       1         3            3          0          4          0            12           1           2         0           2            5            6       1961          1961          1         0           10           12         0.0          3          4           1         3         3             3             4       468.0             3       144.0      270.0        882.0        0          4           1           3       896         0             0        896           0.0           0.0         1         0             2             1            3             5           6           0           1       1961.0             2         1.0       730.0           3           4           2         140            0              0          0          120         0        0       6    2010         8              4\n",
      "1  1462          20         3         81.0    14267       1         0            3          0          0          0            12           2           2         0           2            6            6       1958          1958          3         0           11           13       108.0          3          4           1         3         3             3             0       923.0             5         0.0      406.0       1329.0        0          4           1           3      1329         0             0       1329           0.0           0.0         1         1             3             1            2             6           6           0           1       1958.0             2         1.0       312.0           3           4           2         393           36              0          0            0         0    12500       6    2010         8              4\n",
      "2  1463          60         3         74.0    13830       1         0            3          0          4          0             8           2           2         0           4            5            5       1997          1998          1         0           10           12         0.0          3          4           2         2         3             3             2       791.0             5         0.0      137.0        928.0        0          2           1           3       928       701             0       1629           0.0           0.0         2         1             3             1            3             6           6           1           1       1997.0             0         2.0       482.0           3           4           2         212           34              0          0            0         0        0       3    2010         8              4\n",
      "3  1464          60         3         78.0     9978       1         0            3          0          4          0             8           2           2         0           4            6            6       1998          1998          1         0           10           12        20.0          3          4           2         3         3             3             2       602.0             5         0.0      324.0        926.0        0          0           1           3       926       678             0       1604           0.0           0.0         2         1             3             1            2             7           6           1           1       1998.0             0         2.0       470.0           3           4           2         360           36              0          0            0         0        0       6    2010         8              4\n",
      "4  1465         120         3         43.0     5005       1         0            1          0          4          0            22           2           2         4           2            8            5       1992          1992          1         0            6            6         0.0          2          4           2         2         3             3             0       263.0             5         0.0     1017.0       1280.0        0          0           1           3      1280         0             0       1280           0.0           0.0         2         0             2             1            2             5           6           0           1       1992.0             1         2.0       506.0           3           4           2           0           82              0          0          144         0        0       1    2010         8              4\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "\n",
    "\n",
    "# function that separates all the categories into labeled numbers\n",
    "def Label_encode(x, x_info, x_test):\n",
    "    object_columns = x_info.loc[x_info[\"datatype\"] == \"object\"].index.tolist()\n",
    "    print(object_columns)\n",
    "    x[object_columns] = x[object_columns].astype(\"category\")\n",
    "    x_test[object_columns] = x_test[object_columns].astype(\"category\")\n",
    "    x[object_columns] = x[object_columns].apply(lambda col: col.cat.codes)\n",
    "    x_test[object_columns] = x_test[object_columns].apply(lambda col: col.cat.codes)\n",
    "    x_info = general_info(x)\n",
    "    return x, x_info, object_columns, x_test\n",
    "\n",
    "\n",
    "df, info, objectColumns, df_test = Label_encode(df, info, df_test)\n",
    "\n",
    "\n",
    "def OH_encode(x, x_info):\n",
    "    object_columns = x_info.loc[x_info[\"datatype\"] == \"object\"].index.tolist()\n",
    "    x = pd.get_dummies(x, columns=object_columns, drop_first=False)\n",
    "    x_info = general_info(x)\n",
    "    return x, x_info\n",
    "\n",
    "\n",
    "# df, info = OH_encode(df, info)\n",
    "print(df.head())\n",
    "print(df_test.head())\n",
    "# print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the Data to fit testing requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 74)\n",
      "(1460,)\n"
     ]
    }
   ],
   "source": [
    "# prepare inputs and outputs for training and testing\n",
    "# Split the data\n",
    "x = df.drop(\"SalePrice\", axis=1)\n",
    "y = df[\"SalePrice\"]\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "y = np.log1p(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model = PCA(n_components = 60)\\nx_train = model.fit_transform(x_train)\\nx_test = model.transform(x_test)'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model = PCA(n_components = 60)\n",
    "x_train = model.fit_transform(x_train)\n",
    "x_test = model.transform(x_test)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01445348 -0.01884542 -0.02033203 -0.01335542 -0.01800175]\n"
     ]
    }
   ],
   "source": [
    "# used only for StackingRegressor\n",
    "'''\n",
    "baseModels = [('rf',RandomForestRegressor(n_estimators=50)),('xgb',XGBRegressor())]\n",
    "finalModel = Lasso()\n",
    "'''\n",
    "\n",
    "\n",
    "# initialize the model\n",
    "# model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "# model = GradientBoostingRegressor()\n",
    "# model = StackingRegressor( estimators=baseModels,final_estimator=finalModel,cv =5)\n",
    "# model = Lasso();\n",
    "'''\n",
    "model = XGBRegressor();\n",
    "modelHyp =  {\n",
    "    'n_estimators': [50, 100, 150, 200],                   # Number of boosting rounds\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],               # Step size shrinkage\n",
    "    'max_depth': [3, 5, 7, 9],                             # Maximum depth of a tree\n",
    "    'min_child_weight': [1, 3, 5, 7],                      # Minimum sum of instance weight\n",
    "    'subsample': [0.6, 0.8, 1.0],                          # Fraction of samples used for fitting trees\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],                   # Fraction of features used to build each tree\n",
    "    'gamma': [0, 0.1, 0.2, 0.3],                           # Minimum loss reduction required for partition\n",
    "    'alpha': [0, 0.1, 0.5, 1.0],                           # L1 regularization term\n",
    "    'lambda': [1, 1.5, 2, 5],                              # L2 regularization term\n",
    "    'booster': ['gbtree', 'gblinear', 'dart'],              # Type of boosting model\n",
    "    'scale_pos_weight': [1, 2, 3, 5]                       # Weight of positive class in binary classification\n",
    "}\n",
    "\n",
    "rcv = RandomizedSearchCV( model, param_distributions=modelHyp, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "# run the model\n",
    "rcv.fit(x,y)\n",
    "print(rcv.best_score_)\n",
    "print(rcv.best_params_)\n",
    "\n",
    "# results from running RCV\n",
    "{\n",
    "    \"subsample\": 0.8,\n",
    "    \"scale_pos_weight\": 3,\n",
    "    \"n_estimators\": 200,\n",
    "    \"min_child_weight\": 3,\n",
    "    \"max_depth\": 5,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"lambda\": 1,\n",
    "    \"gamma\": 0,\n",
    "    \"colsample_bytree\": 1.0,\n",
    "    \"booster\": \"dart\",\n",
    "    \"alpha\": 1.0,\n",
    "}\n",
    "'''\n",
    "'''\n",
    "model = XGBRegressor();\n",
    "modelHyp =  {\n",
    "    'n_estimators': [50, 100, 150, 200],                   # Number of boosting rounds\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],               # Step size shrinkage\n",
    "    'max_depth': [3, 5, 7, 9],                             # Maximum depth of a tree\n",
    "    'min_child_weight': [1, 3, 5, 7],                      # Minimum sum of instance weight\n",
    "    'subsample': [0.6, 0.8, 1.0],                          # Fraction of samples used for fitting trees\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],                   # Fraction of features used to build each tree\n",
    "    'gamma': [0, 0.1, 0.2, 0.3],                           # Minimum loss reduction required for partition\n",
    "    'alpha': [0, 0.1, 0.5, 1.0],                           # L1 regularization term\n",
    "    'lambda': [1, 1.5, 2, 5],                              # L2 regularization term\n",
    "    'booster': ['gbtree', 'gblinear', 'dart'],              # Type of boosting model\n",
    "    'scale_pos_weight': [1, 2, 3, 5]                       # Weight of positive class in binary classification\n",
    "}\n",
    "\n",
    "rcv = RandomizedSearchCV( model, param_distributions=modelHyp, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "# run the model\n",
    "rcv.fit(x,y)\n",
    "print(rcv.best_score_)\n",
    "print(rcv.best_params_)\n",
    "\n",
    "# results from running RCV\n",
    "{\n",
    "    \"subsample\": 0.8,\n",
    "    \"scale_pos_weight\": 3,\n",
    "    \"n_estimators\": 200,\n",
    "    \"min_child_weight\": 3,\n",
    "    \"max_depth\": 5,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"lambda\": 1,\n",
    "    \"gamma\": 0,\n",
    "    \"colsample_bytree\": 1.0,\n",
    "    \"booster\": \"dart\",\n",
    "    \"alpha\": 1.0,\n",
    "}\n",
    "'''\n",
    "\n",
    "# Define your XGBRegressor model with the desired hyperparameters\n",
    "model = XGBRegressor(\n",
    "    subsample=0.8,\n",
    "    scale_pos_weight=3,\n",
    "    n_estimators=200,\n",
    "    min_child_weight=3,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    reg_lambda=1,\n",
    "    gamma=0,\n",
    "    colsample_bytree=1.0,\n",
    "    booster=\"dart\",\n",
    "    reg_alpha=1.0,\n",
    ")\n",
    "model.fit(x,y)\n",
    "# Perform cross-validation with negative mean squared error scoring\n",
    "print(cross_val_score(model, x, y, cv=5, scoring=\"neg_mean_squared_error\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Model on Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[126137.07 156395.36 182474.   ... 160259.39 110193.21 211366.1 ]\n",
      "        Id      SalePrice\n",
      "0     1461  126137.070312\n",
      "1     1462  156395.359375\n",
      "2     1463  182474.000000\n",
      "3     1464  191656.187500\n",
      "4     1465  185739.140625\n",
      "...    ...            ...\n",
      "1454  2915   77265.617188\n",
      "1455  2916   76530.859375\n",
      "1456  2917  160259.390625\n",
      "1457  2918  110193.210938\n",
      "1458  2919  211366.093750\n",
      "\n",
      "[1459 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(df_test)\n",
    "SalePrice = np.expm1(y_pred)\n",
    "SalePrice = (SalePrice/100)*100\n",
    "print(SalePrice)\n",
    "submission = pd.DataFrame({'Id':df_test['Id'],'SalePrice':SalePrice.flatten()})\n",
    "print(submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Id  SalePrice\n",
      "0  1461  126137.07\n",
      "1  1462  156395.36\n",
      "2  1463  182474.00\n",
      "3  1464  191656.19\n",
      "4  1465  185739.14\n"
     ]
    }
   ],
   "source": [
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(pd.read_csv(\"submission.csv\").head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
